# Brazillian-Ecommerce-Azure-and-Databricks-Data-Engineering-Project

# Core Description

Built an end-to-end data engineering pipeline for Brazilian e-commerce data using Azure Data Factory, Databricks, ADLS Gen2, and Delta Lake to ingest, transform, and serve data for analytics.  

Implemented a Medallion architecture (Bronze â†’ Silver â†’ Gold) to ensure scalable, reliable data refinement and accessibility.  



# ðŸ›  Technical Responsibilities

Orchestrated data ingestion workflows using Azure Data Factory to capture raw e-commerce datasets (CSV/HTTP/DB sources) into ADLS Gen2.  

Developed PySpark transformation logic in Azure Databricks, performing cleaning, joins, enrichments, and schema standardization at scale.  

Structured data into Delta Lake layers to maintain schema enforcement, versioning, and performance optimization.  



# ðŸ“Š Data Modeling & Processing

Designed and implemented SQL and Spark code to refine raw data into analytics-ready tables and key business metrics.  

Integrated multi-source enrichment (e.g., relational & semi-structured data) to enhance downstream analytics quality.  



# ðŸš€ Insights & Output

Produced ready-to-use refined data layers that can be consumed by visualization tools (e.g., Power BI, Synapse SQL) for dashboards and business insight generation.  

Packaged results and documentation (architecture diagrams, notebooks, SQL scripts) to support reproducibility and future extension. 


# ðŸ§  Skills & Tools Highlight

Cloud Platform: Microsoft Azure (Data Factory, ADLS Gen2, Databricks)  

Big Data Processing: PySpark, Delta Lake, SQL  

Architectural Patterns: Medallion Layers, ETL/ELT workflows  

Version Control & Collaboration: GitHub repo with notebooks and deployment scripts
